{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFBB\">\n",
    "<img src=\"greenforce-logo.png\", width=500, border=20, ALIGN=\"middle\"> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFBB\">\n",
    "    <h3> Céline YAN, Ryad MEDJADI, Circé CARLETTI, Léo RESSAYRE </h3>\n",
    "    <br>\n",
    "        <h1>Team GAIASAVERS</h1>\n",
    "        <img src=\"logo.jpg\", width=150, ALIGN=\"left\", border=20>\n",
    "    <br>\n",
    "    <h3> Sur la base d'un projet créé par : Alban Petit, Wafa Bouzouita,Timothée Babinet, Maxime Chor, Eric Wang, Sebastien Warichet</h3>\n",
    "    <br>\n",
    "    <br>\n",
    "    <h2>Plankton classification challenge</h2>\n",
    "\n",
    "<br>This code was tested with <br>\n",
    "Python 3.7 |Anaconda custom (64-bit)| (default, Jun 28 2018, 11:07:29) (https://anaconda.org/)<br>\n",
    "<i> Adapted for Chalab by Isabelle Guyon from original code of Balázs Kégl</i> <br>\n",
    "<a href=\"http://www.datascience-paris-saclay.fr\">Paris Saclay Center for Data Science (CDS)</a>\n",
    "</center>\n",
    "<p>\n",
    "ALL INFORMATION, SOFTWARE, DOCUMENTATION, AND DATA ARE PROVIDED \"AS-IS\". The CDS, CHALEARN, AND/OR OTHER ORGANIZERS OR CODE AUTHORS DISCLAIM ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR ANY PARTICULAR PURPOSE, AND THE WARRANTY OF NON-INFRIGEMENT OF ANY THIRD PARTY'S INTELLECTUAL PROPERTY RIGHTS. IN NO EVENT SHALL AUTHORS AND ORGANIZERS BE LIABLE FOR ANY SPECIAL, \n",
    "INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF SOFTWARE, DOCUMENTS, MATERIALS, PUBLICATIONS, OR INFORMATION MADE AVAILABLE FOR THE CHALLENGE. \n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h2>Introduction </h2>\n",
    "     <br>\n",
    "       \n",
    "According to [NRMA15], a link has been found between the quality of water and the presence of plankton in said water. As water quality increases, the abundance and diversity of plankton does as well. The aim of our project is to build a plankton classifier to assess water quality.\n",
    "\n",
    "We use for this problem the Bering Sea dataset, an in situ plankton dataset published in May 2019 by Kaichang Cheng [Che19]. This datset contains 7 classes with an even spread.\n",
    "\n",
    "        \n",
    "References and credits: \n",
    "- [NRMA15] A. Nair, J.K. Reshma, A. Mathew, and A. Ashok. Effect of water quality on phytoplankton abundance in selected ponds of nedumangad block panchayat, kerala. Emer Life Sci Res, 2015.\n",
    "- [Che19] K. Cheng. Bering sea dataset. https://doi.org/10.6084/m9.figshare.8146283.v3, 2019.\n",
    " <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/sample.png\" alt=\"Drawing\"/>\n",
    "To see more images for each class, see the \"images\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'sample_code_submission/'       \n",
    "result_dir = 'sample_result_submission/' \n",
    "problem_dir = 'ingestion_program/'  \n",
    "score_dir = 'scoring_program/'\n",
    "from sys import path; path.append(model_dir); path.append(problem_dir); path.append(score_dir); \n",
    "%matplotlib inline\n",
    "# Uncomment the next lines to auto-reload libraries (this causes some problem with pickles in Python 3)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import seaborn as sns; sns.set()\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h1> Step 1: Exploratory data analysis </h1>\n",
    "<p>\n",
    "We provide sample_data with the starting kit, but to prepare your submission, you must fetch the public_data from the challenge website and point to it.\n",
    "    <br>\n",
    "    <span style=\"color:red\"> Just change the data name in the block below. In the rest of the section, replace the sample plots by anything you want. </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plankton_feat.name    plankton_test.data       plankton_valid.data\r\n",
      "plankton_label.name   plankton_train.data\r\n",
      "plankton_public.info  plankton_train.solution\r\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'public_data'              # Change this to the directory where you put the input data\n",
    "#data_dir = '../public_data'          # The sample_data directory should contain only a very small subset of the data\n",
    "data_name = 'plankton'\n",
    "!ls $data_dir*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Two \"feature representation\"</h3>\n",
    "\n",
    "<p>\n",
    "1.\n",
    "All of the images are in various shades of gray. As such, we can represent every image by a vector of 90000 (300x300) features where each feature is a float value between 0 and 255 representing the brightness of a pixel (0 being a black pixel and 255 a white one). It is also possible to reduce the size of the images to reduce the number of features as seen in figure 3 where we reduced the size to 100x100 pixels.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td> <img src=\"images/gray.png\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "    <td> <img src=\"images/binarized.png\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "</tr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "2. At first we will have four types of \"features\". Two \"features\" are applied on the binarized images.\n",
    "    <ul>\n",
    "        <li>The first is a sum of black pixels, per line and per column.\n",
    "This gives us 2 vectors of size 100. These \"features\" are representative among others of the shape of the plankton.\n",
    "For round seeders the ratio between rows and columns near the center of the image should be close.\n",
    "For longer plankton the ratio will be either low or high, depending on plankton position.\n",
    "        </li>\n",
    "        <li>The second is the average of the pixels.\n",
    "            This gives us information on the size of the plankton.\n",
    "        </li>\n",
    "        <li>The third feature is the variance and is applied to non-binarized images.</li>\n",
    "        <li>The last feature is the length of the contour of the plankton. It is obtained by applying a sobel filter on the image. This filter will put black pixels on the contours and white ones everywhere else. We can then just compute the amount of black pixels.\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we load the data as a \"pandas\" data frame, so we can use \"pandas\" and \"seaborn\" built in functions to explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading public_data/plankton_train from AutoML format\n",
      "Number of examples = 10752\n",
      "Number of features = 203\n",
      "          Class\n",
      "0  chaetognatha\n",
      "1      copepoda\n",
      "2   euphausiids\n",
      "3   fish_larvae\n",
      "4      limacina\n",
      "5       medusae\n",
      "6         other\n",
      "Number of classes = 7\n"
     ]
    }
   ],
   "source": [
    "from data_io import read_as_df\n",
    "data = read_as_df(data_dir  + '/' + data_name)                # The data are loaded as a Pandas Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the distribution of labels in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copepoda        1536\n",
       "fish_larvae     1536\n",
       "euphausiids     1536\n",
       "limacina        1536\n",
       "medusae         1536\n",
       "other           1536\n",
       "chaetognatha    1536\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_axis_0_0</th>\n",
       "      <th>sum_axis_0_1</th>\n",
       "      <th>sum_axis_0_2</th>\n",
       "      <th>sum_axis_0_3</th>\n",
       "      <th>sum_axis_0_4</th>\n",
       "      <th>sum_axis_0_5</th>\n",
       "      <th>sum_axis_0_6</th>\n",
       "      <th>sum_axis_0_7</th>\n",
       "      <th>sum_axis_0_8</th>\n",
       "      <th>sum_axis_0_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sum_axis_1_94</th>\n",
       "      <th>sum_axis_1_95</th>\n",
       "      <th>sum_axis_1_96</th>\n",
       "      <th>sum_axis_1_97</th>\n",
       "      <th>sum_axis_1_98</th>\n",
       "      <th>sum_axis_1_99</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "      <th>outline_length</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.83871</td>\n",
       "      <td>0.83871</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.744560</td>\n",
       "      <td>0.062088</td>\n",
       "      <td>9.82</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852347</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>0.64</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.82000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.478031</td>\n",
       "      <td>0.130620</td>\n",
       "      <td>6.68</td>\n",
       "      <td>limacina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96000</td>\n",
       "      <td>0.99000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.799294</td>\n",
       "      <td>0.037921</td>\n",
       "      <td>6.86</td>\n",
       "      <td>chaetognatha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.99000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.713423</td>\n",
       "      <td>0.065195</td>\n",
       "      <td>11.56</td>\n",
       "      <td>medusae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sum_axis_0_0  sum_axis_0_1  sum_axis_0_2  sum_axis_0_3  sum_axis_0_4  \\\n",
       "0           1.0           1.0          1.00          1.00          1.00   \n",
       "1           1.0           1.0          1.00          1.00          1.00   \n",
       "2           1.0           1.0          1.00          1.00          1.00   \n",
       "3           1.0           1.0          0.99          0.96          0.94   \n",
       "4           1.0           1.0          1.00          1.00          1.00   \n",
       "\n",
       "   sum_axis_0_5  sum_axis_0_6  sum_axis_0_7  sum_axis_0_8  sum_axis_0_9  ...  \\\n",
       "0          1.00          1.00          1.00          1.00          1.00  ...   \n",
       "1          1.00          1.00          1.00          1.00          1.00  ...   \n",
       "2          1.00          1.00          1.00          1.00          1.00  ...   \n",
       "3          0.94          0.92          0.92          0.92          0.93  ...   \n",
       "4          1.00          1.00          1.00          1.00          1.00  ...   \n",
       "\n",
       "   sum_axis_1_94  sum_axis_1_95  sum_axis_1_96  sum_axis_1_97  sum_axis_1_98  \\\n",
       "0        0.83871        0.83871       0.827957       0.817204       0.795699   \n",
       "1        1.00000        1.00000       1.000000       1.000000       1.000000   \n",
       "2        0.82000        0.90000       1.000000       1.000000       1.000000   \n",
       "3        0.96000        0.99000       1.000000       1.000000       1.000000   \n",
       "4        1.00000        0.99000       0.990000       0.990000       1.000000   \n",
       "\n",
       "   sum_axis_1_99      mean  variance  outline_length        target  \n",
       "0       0.774194  0.744560  0.062088            9.82         other  \n",
       "1       1.000000  0.852347  0.021939            0.64         other  \n",
       "2       1.000000  0.478031  0.130620            6.68      limacina  \n",
       "3       1.000000  0.799294  0.037921            6.86  chaetognatha  \n",
       "4       1.000000  0.713423  0.065195           11.56       medusae  \n",
       "\n",
       "[5 rows x 204 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some statistics about the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_axis_0_0</th>\n",
       "      <th>sum_axis_0_1</th>\n",
       "      <th>sum_axis_0_2</th>\n",
       "      <th>sum_axis_0_3</th>\n",
       "      <th>sum_axis_0_4</th>\n",
       "      <th>sum_axis_0_5</th>\n",
       "      <th>sum_axis_0_6</th>\n",
       "      <th>sum_axis_0_7</th>\n",
       "      <th>sum_axis_0_8</th>\n",
       "      <th>sum_axis_0_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sum_axis_1_93</th>\n",
       "      <th>sum_axis_1_94</th>\n",
       "      <th>sum_axis_1_95</th>\n",
       "      <th>sum_axis_1_96</th>\n",
       "      <th>sum_axis_1_97</th>\n",
       "      <th>sum_axis_1_98</th>\n",
       "      <th>sum_axis_1_99</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "      <th>outline_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "      <td>10752.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.979279</td>\n",
       "      <td>0.977036</td>\n",
       "      <td>0.972997</td>\n",
       "      <td>0.965795</td>\n",
       "      <td>0.956058</td>\n",
       "      <td>0.946609</td>\n",
       "      <td>0.938161</td>\n",
       "      <td>0.930047</td>\n",
       "      <td>0.922546</td>\n",
       "      <td>0.914766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936903</td>\n",
       "      <td>0.943581</td>\n",
       "      <td>0.951833</td>\n",
       "      <td>0.961342</td>\n",
       "      <td>0.966297</td>\n",
       "      <td>0.970557</td>\n",
       "      <td>0.971949</td>\n",
       "      <td>0.677502</td>\n",
       "      <td>0.074303</td>\n",
       "      <td>8.117898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.096922</td>\n",
       "      <td>0.098681</td>\n",
       "      <td>0.099546</td>\n",
       "      <td>0.102380</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.113165</td>\n",
       "      <td>0.119380</td>\n",
       "      <td>0.126461</td>\n",
       "      <td>0.132001</td>\n",
       "      <td>0.138568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118902</td>\n",
       "      <td>0.114981</td>\n",
       "      <td>0.110555</td>\n",
       "      <td>0.106497</td>\n",
       "      <td>0.105424</td>\n",
       "      <td>0.104636</td>\n",
       "      <td>0.105878</td>\n",
       "      <td>0.133997</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>4.244094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.209394</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.582888</td>\n",
       "      <td>0.049183</td>\n",
       "      <td>5.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.694925</td>\n",
       "      <td>0.068188</td>\n",
       "      <td>6.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.782364</td>\n",
       "      <td>0.094579</td>\n",
       "      <td>9.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969234</td>\n",
       "      <td>0.214556</td>\n",
       "      <td>31.030000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sum_axis_0_0  sum_axis_0_1  sum_axis_0_2  sum_axis_0_3  sum_axis_0_4  \\\n",
       "count  10752.000000  10752.000000  10752.000000  10752.000000  10752.000000   \n",
       "mean       0.979279      0.977036      0.972997      0.965795      0.956058   \n",
       "std        0.096922      0.098681      0.099546      0.102380      0.106950   \n",
       "min        0.100000      0.050000      0.070000      0.030000      0.040000   \n",
       "25%        1.000000      1.000000      1.000000      0.990000      0.960000   \n",
       "50%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "75%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       sum_axis_0_5  sum_axis_0_6  sum_axis_0_7  sum_axis_0_8  sum_axis_0_9  \\\n",
       "count  10752.000000  10752.000000  10752.000000  10752.000000  10752.000000   \n",
       "mean       0.946609      0.938161      0.930047      0.922546      0.914766   \n",
       "std        0.113165      0.119380      0.126461      0.132001      0.138568   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.940000      0.930000      0.916667      0.900000      0.880000   \n",
       "50%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "75%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...  sum_axis_1_93  sum_axis_1_94  sum_axis_1_95  sum_axis_1_96  \\\n",
       "count  ...   10752.000000   10752.000000   10752.000000   10752.000000   \n",
       "mean   ...       0.936903       0.943581       0.951833       0.961342   \n",
       "std    ...       0.118902       0.114981       0.110555       0.106497   \n",
       "min    ...       0.000000       0.000000       0.000000       0.000000   \n",
       "25%    ...       0.920000       0.940000       0.950000       0.980000   \n",
       "50%    ...       1.000000       1.000000       1.000000       1.000000   \n",
       "75%    ...       1.000000       1.000000       1.000000       1.000000   \n",
       "max    ...       1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       sum_axis_1_97  sum_axis_1_98  sum_axis_1_99          mean  \\\n",
       "count   10752.000000   10752.000000   10752.000000  10752.000000   \n",
       "mean        0.966297       0.970557       0.971949      0.677502   \n",
       "std         0.105424       0.104636       0.105878      0.133997   \n",
       "min         0.000000       0.010000       0.040000      0.209394   \n",
       "25%         1.000000       1.000000       1.000000      0.582888   \n",
       "50%         1.000000       1.000000       1.000000      0.694925   \n",
       "75%         1.000000       1.000000       1.000000      0.782364   \n",
       "max         1.000000       1.000000       1.000000      0.969234   \n",
       "\n",
       "           variance  outline_length  \n",
       "count  10752.000000    10752.000000  \n",
       "mean       0.074303        8.117898  \n",
       "std        0.033898        4.244094  \n",
       "min        0.001928        0.000000  \n",
       "25%        0.049183        5.740000  \n",
       "50%        0.068188        6.720000  \n",
       "75%        0.094579        9.102500  \n",
       "max        0.214556       31.030000  \n",
       "\n",
       "[8 rows x 203 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[['sum_axis_0_50','sum_axis_1_50','mean','variance', 'outline_length']].hist(figsize=(10, 10), bins=50, layout=(3, 2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "data_target = data.copy()\n",
    "le = preprocessing.LabelEncoder()\n",
    "data_target.target = le.fit_transform(data_target.target.values)\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "sns.heatmap(data_target[['sum_axis_0_50','sum_axis_1_50','mean','variance','outline_length','target']].corr(), annot = True)\n",
    "plt.title('Correlation_matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(data,hue='target',vars=['sum_axis_0_50','sum_axis_1_50','mean','variance','outline_length'])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "<h1>Step 2: Building a predictive model</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h2>Loading data with DataManager</h2>\n",
    "    <p>\n",
    "We reload the data with the AutoML DataManager class because this is more convenient:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data_manager import DataManager\n",
    "D = DataManager(data_name, data_dir, replace_missing=True)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h2>Training a predictive model</h2>\n",
    "    <p>\n",
    "We provide an example of predictive model (for classification or regression) in the `sample_code_submission/` directory. It is a quite stupid model: it makes constant predictions. Replace it with your own model.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_io import write\n",
    "from model import model\n",
    "from modelComparer import modelComparer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "an instance of the model (run the constructor) and attempt to reload a previously saved version from `sample_code_submission/`:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libscores import get_metric\n",
    "metric_name, scoring_function = get_metric()\n",
    "print('Using scoring metric:', metric_name)\n",
    "# Uncomment the next line to display the code of the scoring metric\n",
    "#??scoring_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_name = model_dir + data_name\n",
    "\n",
    "# Uncomment the next line to re-load an already trained model\n",
    "#M = model()\n",
    "#M = M.load(trained_model_name)                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Train the model (unless you reloaded a trained model) and make predictions. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ PREPROCESSING ###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changer X_train et X_valid\n",
    "X_t = D.data['X_train']\n",
    "Y = D.data['Y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "X_scaled = preprocessing.scale(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de l'algorithme Isolation Forest pour prédire les outliers\n",
    "from sklearn.ensemble import IsolationForest\n",
    "# Pour avoir la 2D\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(X_scaled)\n",
    "X_scaled_transformed = pca.transform(X_scaled)\n",
    "clf = IsolationForest(random_state=0).fit(X_scaled)\n",
    "clf.fit(X_scaled)\n",
    "# Prédit les outliers (nombres négatifs)\n",
    "prediction = clf.predict(X_scaled)\n",
    "# Donne le score d'anomalie moyen\n",
    "#clf.decision_function(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=read_as_df(data_dir + \"/\" + data_name)\n",
    "# Affichage des outliers avec scatterplot\n",
    "sns.scatterplot(x=\"sum_axis_1_50\", y=\"variance\", data=data, hue=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En variant le nombre de dimensions :\n",
    "# Dim 2 -> 0.5182\n",
    "# Dim 40 -> 0.5980\n",
    "# Dim 45 -> 0.5563\n",
    "# Dim 50 -> 0.6108\n",
    "# Dim 55 -> 0.5523\n",
    "# Dim 75 -> 0.5850\n",
    "# Dim 100 -> 0.5951\n",
    "# Dim 150 -> 0.5729"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#AA5544\">\n",
    "    <h2 style = 'color:grey'>Partie Modèle README</h2>\n",
    "    <p style = 'color:grey'> Dans cette partie nous entrainons et sélectionnons un modèle et ses paramètres\n",
    "    </p>\n",
    "    <h3 style = 'color:grey'>PROBLEMES</h3>\n",
    "    <p style = 'color:grey'>Le problème que nous avons est le warning qui est signalé\n",
    "    lors des éxécutions (cf: Entrée 23), warnings qui posent problème quand on tente de faire fonctionner \n",
    "    la fonction sklearn: ValidationCurve qui permet de faire varier un paramètre et de retourner\n",
    "        les tableaux contenants les scores pour chaques valeurs des \n",
    "        paramètres. Cette fonction fonctionne bien pour le classifier\n",
    "        DecisionTree mais pour le RandomForestClassifier, on nous affiche des warnings \n",
    "        en masse sans que laffichage escompté ne survienne, comme si lordinateur \n",
    "        narrivait pas à sortir dune boucle. \n",
    "    </p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ MODEL ################################################\n",
    "############ Partie des imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "############ Création des tableaux de données \n",
    "# Dans ce qui suit on peut dé-commenter une des deux parties et\n",
    "#commenter l'autre pour utiliser ou non le pre-processing du groupe\n",
    "\n",
    "#Partie I : pour utiliser le pre-processing du groupe\n",
    "\n",
    "#X = X_scaled_transformed\n",
    "#X_train, X_valid, Y_train, Y_valid = train_test_split( X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "#Partie II: pour utiliser le pre-proccessing donné par les profeseurs\n",
    "print(\"========\")\n",
    "print(X_t.shape)\n",
    "print(Y.shape)\n",
    "print(\"========\")\n",
    "\n",
    "#X_t = X_t.ravel()\n",
    "Y = Y.ravel()\n",
    "print(\"========\")\n",
    "print(X_t.shape)\n",
    "print(Y.shape)\n",
    "print(\"========\")\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split( X_t, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "#Modification du 05/04: Malgré les quatres lignes ci-dessous, les warnings \n",
    "#s'affichent quand même\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "#TESTS de \"reshapage\" qui n'ont pas fonctionnés\n",
    "#Y.reshape(10752)\n",
    "#Y.ravel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Partie de sélection de modèle\n",
    "#Dans cette partie nous utilisons la classe modelComparer\n",
    "#que nous avons créé (cf: /sample_code_submission/modelComparer)\n",
    "\n",
    "#Création puis affichage du comparateur\n",
    "print(\"Création du modelComparer..\")\n",
    "modelTest = modelComparer(\"DecisionTreeClassifier\", DecisionTreeClassifier(max_depth=10, max_features = 'sqrt',random_state=42))\n",
    "modelTest.addClassifier(\"OneVsOneClassifier\",OneVsOneClassifier(SGDClassifier(random_state=42)))\n",
    "modelTest.addClassifier(\"AdaBoostClassifier\",AdaBoostClassifier(n_estimators=100))\n",
    "modelTest.addClassifier(\"RandomForestClassifier\",RandomForestClassifier(n_estimators=180, max_depth=None, max_features='auto'))\n",
    "modelTest.addClassifier(\"KNeighborsClassifier\",neighbors.KNeighborsClassifier(n_neighbors=7))\n",
    "modelTest.showClasses()\n",
    "\n",
    "#Fonction 'fit' pour tous les modèles\n",
    "modelTest.fitAll(X_train,Y_train)\n",
    "\n",
    "#Fonction de comparaison\n",
    "modelTest.comparingFunction(X_train,Y_train,X_valid,Y_valid,5)\n",
    "\n",
    "#Fonction de ValidationCurve pôur le choix des paramètres\n",
    "#WARNING 04/04: NE FONCTIONNE PAS ENTIEREMENT\n",
    "#Dé-commenter pour voir le résultat\n",
    "#I) Ne foncitonne pas (décommenter pour voir le problème: pour les\n",
    "#classifiers RandomForestClassifier, ou encore KNeighborsClassifier\n",
    "#la fonciton ci-dessous 'showValidationCurve', définit \n",
    "#dans /sample_core_submission/modelComparer.py, affiche les warnings en boucle\n",
    "#sans jamais s'arrêter.)\n",
    "modelTest.showValidationCurve(4,X_train,Y_train,'n_estimators',150 ,200 , 5)\n",
    "#II) Fonctionne\n",
    "#modelTest.showValidationCurve(1,X_train,Y_train,'max_depth',1,50, 5)\n",
    "\n",
    "#modelTest_2 = RandomForestClassifier()\n",
    "#modelTest.addClassifier(\"RandomForestClassifier_2\", modelTest_2)\n",
    "#param_grid={'n_estimators' : np.arange(190,200), 'max_depth':np.arange(1,10), 'min_samples_split':np.arange(2,10), 'random_state':np.arange(0,10), 'criterion':['gini', 'entropy']}\n",
    "#modelTest.showGridSearchCV(6, X_train, Y_train, X_valid, Y_valid,param_grid, 2)\n",
    "#Création des Y_hat_ utiles pour /sample_result_submission\n",
    "Y_hat_train = modelTest.predictOne(4,X_train)\n",
    "Y_hat_valid = modelTest.predictOne(4,X_valid)\n",
    "\n",
    "#Validation du classifier choisi\n",
    "M = modelTest.getClassifier(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <b> Save the trained model </b> (will be ready to reload next time around) and save the prediction results. IMPORTANT: if you save the trained model, it will be bundled with your sample code submission. Therefore your model will NOT be retrained on the challenge platform. Remove the pickle from the submission if you want the model to be retrained on the platform.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTest.save(4,trained_model_name)                 \n",
    "result_name = result_dir + data_name\n",
    "from data_io import write\n",
    "write(result_name + '_train.predict', Y_hat_train)\n",
    "write(result_name + '_valid.predict', Y_hat_valid)\n",
    "#write(result_name + '_test.predict', Y_hat_test)\n",
    "!ls $result_name*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h2>Scoring the results</h2>\n",
    "    <h3>Load the challenge metric</h3>\n",
    "    <p>\n",
    "<b>The metric chosen for your challenge</b> is identified in the \"metric.txt\" file found in the `scoring_function/` directory. The function \"get_metric\" searches first for a metric having that name in my_metric.py, then in libscores.py, then in sklearn.metric.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "The chosen metric is the balanced accuracy. It computes the proportion of elements correctly predicted for each class. It then returns the mean of these values. The advantage of this metric is that every class is given an equal weight. <br> In our case, since all the classes are perfectly balanced, it is equivalent to simply computing the accuracy score but it the case the test set is changed and is no longer balanced, the balanced accuracy will still work properly while the accuracy score will not.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from libscores import get_metric\n",
    "#metric_name, scoring_function = get_metric()\n",
    "#print('Using scoring metric:', metric_name)\n",
    "# Uncomment the next line to display the code of the scoring metric\n",
    "#??scoring_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h3> Training performance </h3>\n",
    "    <p>\n",
    "The participants normally posess target values (labels) only for training examples (except for the sample data). We compute with the `example` metric the training score, which should be zero for perfect predictions.\n",
    "        </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_hat_train))\n",
    "print('Validating score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_valid, Y_hat_valid))\n",
    "print('Ideal score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add here other scores and result visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('default')\n",
    "labels = [\"chaetognatha\",\"copepoda\",\"euphausiids\",\"fish_larvae\",\"limacina\",\"medusae\",\"other\"]\n",
    "cm = confusion_matrix(Y_valid, Y_hat_valid)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:,np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "im = ax.imshow(cm, interpolation='nearest',cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "ax.set(xticks=np.arange(cm.shape[1]),yticks=np.arange(cm.shape[0]),xticklabels=labels,yticklabels=labels,title=\"Confusion matrix\",xlabel=\"Predicted label\",ylabel=\"True label\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "fmt = '.2f'\n",
    "thresh = cm.max()/2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h3>Cross-validation performance</h3>\n",
    "    <p>\n",
    "The participants do not have access to the labels Y_valid and Y_test to self-assess their validation and test performances. But training performance is not a good prediction of validation or test performance. Using cross-validation, the training data is split into multiple training/test folds, which allows participants to self-assess their model during development. The average CV result and 95% confidence interval is displayed.\n",
    "   </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "scores = cross_val_score(M, X_train, Y_train, cv=5, scoring=make_scorer(scoring_function))\n",
    "print('\\nCV score (95 perc. CI): %0.2f (+/- %0.2f)' % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "<h1> Step 3: Making a submission </h1> \n",
    "\n",
    "<h2> Unit testing </h2> \n",
    "\n",
    "It is <b><span style=\"color:red\">important that you test your submission files before submitting them</span></b>. All you have to do to make a submission is modify the file <code>model.py</code> in the <code>sample_code_submission/</code> directory, then run this test to make sure everything works fine. This is the actual program that will be run on the server to test your submission. \n",
    "<br>\n",
    "Keep the sample code simple.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!source activate python3; python $problem_dir/ingestion.py $data_dir $result_dir $problem_dir $model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "Also test the scoring program:\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_output_dir = 'scoring_output'\n",
    "!source activate python3; python $score_dir/score.py $data_dir $result_dir $scoring_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h1> Preparing the submission </h1>\n",
    "\n",
    "Zip the contents of `sample_code_submission/` (without the directory), or download the challenge public_data and run the command in the previous cell, after replacing sample_data by public_data.\n",
    "Then zip the contents of `sample_result_submission/` (without the directory).\n",
    "<b><span style=\"color:red\">Do NOT zip the data with your submissions</span></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "from data_io import zipdir\n",
    "the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "sample_code_submission = './sample_code_submission_' + the_date + '.zip'\n",
    "sample_result_submission = './sample_result_submission_' + the_date + '.zip'\n",
    "zipdir(sample_code_submission, model_dir)\n",
    "zipdir(sample_result_submission, result_dir)\n",
    "print(\"Submit one of these files:\\n\" + sample_code_submission + \"\\n\" + sample_result_submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
